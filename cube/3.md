<div style="text-align:right; color:#aaa">Kristoffer Dyrkorn, May 4, 2024</div>

# Cubes, golfing and dual identities - part 3

In this blog series, we have so far created a small web application, and we have mapped down the source code it consisted of. Here in part 3, we will now compress the source code even more. To achieve this, this time we're going to let our runtime environment — the browser — do most of the work.

It has become very common to turn on compression when static resources (HTML, CSS, JavaScript) are transferred from a server to a browser. Then the server is responsible for the compression, typically using an algorithm called Deflate, and the browser ensures decompression before the resources are processed further. Deflate provides usable compression of static resources (which are, after all, text), typically file sizes will be reduced to a third of their original size.

It would have been interesting to try to make use of this in our case too, i.e. on the code we created in part 1 and then optimized in part 2. The question is then: How? We do not want to become dependent on a server. The source code here must remain completely independent. So we have to come up with something else.

Fortunately for us, someone has already come up with something else! [Cody Brocious](https://github.com/daeken/Benjen/blob/master/daeken.com/entries/superpacking-js-demos.md), aka Daeken, has found a way to further compress code. Let's start by taking a closer look at which other data formats browsers have built-in support for. Image files are one of them. And in some image formats (including PNG) lossless compression is done, sometimes using the Deflate algorithm. Then the browser is responsible for the decompression and this happens transparently for us developers and users. But then the question is: Can we get our code into a PNG? Does it even work?

Yes, it works. Although code is text, code is also just byte values in the same way that the RGB values in images are. So it is actually possible to calculate the code (ie: the ASCII value of each character) as color values, and then put the text stream into a PNG encoder. The result is an image that does not contain anything visually interesting, but it does contain a compressed version of our code.

The next question then becomes how we can unpack the code again and then run it. And this is where this double identity thing comes in. The PNG format has support for so-called "custom chunks". These are metadata blocks internally in the PNG format that you can fill with whatever you want, including text. And thus also HTML and JavaScript. If we let the PNG have the file extension .html, a browser will think that this is an HTML file. And the default behavior for browsers — if they get data they don't understand — is to ignore it and then continue reading. The browser will thus ignore the binary data at the start of the PNG, and when it encounters our custom PNG chunk that contains code, it will try to interpret and run the code. Inside the chunk, we therefore place a decoder for the PNG data — i.e. a small JavaScript program that reads out the byte values from the PNG, translates to ASCII text and then runs the input (the JavaScript that makes up our application).

The procedure is therefore:

- Start with the JavaScript code inside our application
- Create a PNG out of the byte values that the text represents
- Create a custom chunk in the PNG and insert a decoder (written in JavaScript) there
- Let the PNG have the file extension .html

There are [ready-made scripts](https://gist.github.com/gasman/2560551) that can do this job for us. When the browser processes the file, this happens:

- The browser thinks the file contains HTML, but initially sees binary data, so it is ignored
- The browser reaches the decoder and starts running it
- The decoder points to the image data at the beginning of the file, so the browser reads it in again
- The decoder converts each byte to a character, and executes the resulting text string

Thus we have achieved Deflate compression of the code without introducing a server. To achieve this, we use a file that has two identities: It is both a PNG file and an HTML file.

We can now try this out in practice on the code from the previous blog post in this series. We start by looking at the decoder. As mentioned, it must read in the image and extract pixel values. It should do this using as little code as possible, so as not to destroy the gain from the compression that otherwise occurs. The decoder must use a canvas to read out pixel values, and we can simultaneously reuse that canvas in our application itself. If we start from an existing decoder that is quite efficiently written, and apply the same adjustment to the canvas element we did before (setting the width to 99%), it looks like this:

```
<canvas id=c style=width:99%>
<img src=# onload=for(a=c.getContext('2d'),i=e='';a.drawImage(this,i--,0),
t=a.getImageData(0,0,1,1).data[0];)e+=String.fromCharCode(t);eval(e)>
```

Both the canvas element and the graphics context will be available to the code being decoded, so we don't need to repeat the initialization inside the application itself. The code we are going to turn into a PNG can thus be shortened a bit:

```
v=0;w=c.width;m=Math.cos;p=[-1,-1,1,1,-1,1,1,1,1,-1,1,1,-1,-1,-1,1,-1,-1,1,1,-1,-1,1,-1];f="012303740451654762156732".split("");r=[];setInterval('a.clearRect(0,0,w,w);for(i=0;24>i;i++)u=m(v+11),o=m(v),r[i]=p[i]*o-p[i+1]*u,r[i+1]=p[i]*u+p[i+1]*o,r[i+2]=p[i+2]*o-r[i]*u,r[i]=p[i+2]*u+r[i]*o,r[i]=99*r[i]/(5-r[++i+1])+w/2,r[i]=99*r[i]/(5-r[++i])+w/3;for(i=0;24>i;i++){a.beginPath();a.moveTo(r[3*f[i]],r[3*f[i]+1]);s=r[3*f[i]+2];for(j=3;j--;)s+=r[3*f[++i]+2],a.lineTo(r[3*f[i]],r[3*f[i]+1]);a.closePath();a.fillStyle="rgb(0,0,"+(127+32*s|0)+")";.6<s&&a.fill()}v+=.01',9)
```

The result is 555 bytes! However, we now see content from the PNG at the top of the screen, this happens because the image file — even though it consists of binary data — contains some characters that are in the ASCII range for normal letters. We can hide this using some CSS. In our application, we just put in some JavaScript to set the text color of the entire web page to white:

```
body.style="color:#fff";v=0;w=c.width;m=Math.cos;(...)
```

We can also move the CSS we put on the canvas element in the decoder into the application itself. Then we also get to compress that code.

```
c.style="width:99%";body.style="color:#fff";v=0;w=c.width;m=Math.cos;(...)
```

With these changes in place, the code is 565 bytes. Not bad!

How good has the compression actually become? Can we see how much space different parts of the application code take up? There is a suitable tool for this — called gzthermal. Using that program, we can see a kind of color plot of how much space each character in our code takes up. The scale indicates from red (little), via orange, yellow, green and to blue (a lot), how well each character is compressed. If we run gzthermal on the latest version of our code, the result is this:

<p align="center">
<img src="images/gzthermal.png" width="90%">
</p>

Here we can see that text strings that are repeated are compressed well. This also means that API methods that are long will be compressed poorly. Capital letters and special characters will also compress poorly. In order to end up with the shortest possible code in the end, one must both reduce the source code itself and write it so that it is better compressed. Using variable names that are repeated inside other strings will often give good results.

However, to get quick feedback on the degree of compression, you don't need to use `gzthermal`. Google's Closure compiler also provides good information about the compression when processing code there:

<p align="center">
<img src="images/closure_compiler.png" width="90%">
</p>

And with that, this blog series is over. We've created a small application, rewritten the source code to take up little space, and finally created a version of the application that is self-extracting and compressed using the PNG format's built-in Deflate algorithm. We have gone from a size of approx. 1900 bytes down to approx. 560, i.e. a reduction down to 30% of the original, and we have managed to keep almost all the functionality.

Hope this has been interesting! Happy hacking!
